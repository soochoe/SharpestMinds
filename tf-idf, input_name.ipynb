{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FashionGen Dataset - Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this project is to build an apparel recommender system that suggests similar fashion items to users using Natural Language Processing. The dataset is from the FashionGen Challenge which was arranged through the collaboration between SSENSE and ElementAI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "BATCH_SIZE = 500\n",
    "\n",
    "\n",
    "def get_batch(file_h5, features, batch_number, batch_size=32):\n",
    "    \"\"\"Get a batch of the dataset\n",
    "    \n",
    "    Args:\n",
    "        file_h5(str): path of the dataset\n",
    "        features(list(str)): list of names of features present in the dataset\n",
    "            that should be returned.\n",
    "        batch_number(int): the id of the batch to be returned.\n",
    "        batch_size(int): the mini-batch size\n",
    "    Returns:\n",
    "        A list of numpy arrays of the requested features\"\"\"\n",
    "    list_of_arrays = []\n",
    "    lb, ub = batch_number * batch_size, (batch_number + 1) * batch_size\n",
    "    for feature in features:\n",
    "        list_of_arrays.append(file_h5[feature][lb: ub])\n",
    "    return list_of_arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "f = h5py.File('fashiongen_256_256_train.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading h5py file using pandas \n",
    "#a = pd.read_hdf(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = f.get('index')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array(a)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of dimensions for each array x.ndim\n",
    "a.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the column names of the dataset \n",
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data type of columns\n",
    "print(\"name, data type, number of array dimensions\")\n",
    "for row in list(f.keys()):\n",
    "    print(str(row) + \": \" + str(f[row].dtype) + \": \" + str(f[row].ndim))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to convert S100, S200, S800, S40 datatypes to a string. Right away, we can see that all the datasets have an extra array dimension that need to be reduced by 1 except index_2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output numpy arrays to images -  Test to see if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "b=1\n",
    "input2 = ['input_image']\n",
    "list_of_arrays = get_batch(f, input2, a, b)\n",
    "a = np.array(list_of_arrays)\n",
    "#a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "# outputting picture using matplotlib \n",
    "#plt.imshow(a.squeeze())\n",
    "#plt.show()\n",
    "\n",
    "import image \n",
    "from PIL import Image\n",
    "c = a.squeeze()\n",
    "photo = Image.fromarray(c)\n",
    "photo\n",
    "# yay it works! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dataframe  - excluding input_image - size too large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_h5 = h5py.File('fashiongen_256_256_train.h5', mode='r')\n",
    "list_of_features = ['index', 'index_2', 'input_brand', 'input_category', 'input_composition', 'input_concat_description', 'input_department','input_description',\n",
    "'input_gender', 'input_msrpUSD', 'input_name', 'input_pose', 'input_productID', 'input_season', 'input_subcategory']\n",
    "#list_of_features = ['index', 'index_2', 'input_brand', 'input_category', 'input_composition', 'input_concat_description', 'input_department','input_description',\n",
    "# 'input_gender', 'input_image', 'input_msrpUSD', 'input_name', 'input_pose', 'input_productID', 'input_season', 'input_subcategory']\n",
    "\n",
    "dataset_len = len(file_h5['input_image'])\n",
    "nb_batches = int(dataset_len / BATCH_SIZE)\n",
    "\n",
    "batch_nb = np.random.randint(0, nb_batches)\n",
    "\n",
    "# get the first batch of the data\n",
    "test = get_batch(file_h5, list_of_features, batch_nb, BATCH_SIZE)\n",
    "#file_h5.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe that includes all the features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_all_features = ['index', 'index_2', 'input_brand', 'input_category', 'input_composition', 'input_concat_description', 'input_department','input_description',\n",
    "'input_gender', 'input_image','input_msrpUSD', 'input_name', 'input_pose', 'input_productID', 'input_season', 'input_subcategory'] \n",
    "batch_nb1 = 1\n",
    "#Store h5py file in image \n",
    "image = get_batch(file_h5, list_of_all_features, batch_nb1 , BATCH_SIZE)\n",
    "file_h5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default encode is ASCII\n",
    "# decoding - This method is used to convert from one encoding scheme, in which argument string is encoded to the desired encoding scheme\n",
    "# input_brand \n",
    "image[2] = np.char.decode(image[2],\"iso-8859-1\")\n",
    "# input_concat_description\n",
    "image[5] = np.char.decode(image[5],\"iso-8859-1\")\n",
    "# input_description\n",
    "image[7] = np.char.decode(image[7],\"iso-8859-1\")\n",
    "# input_name\n",
    "image[11] = np.char.decode(image[11],\"iso-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image[2].dtype\n",
    "dt = np.dtype('<U21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image[5].dtype\n",
    "dt = np.dtype('<U800')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cp1252 and iso-8859-1 work - https://docs.python.org/2/library/codecs.html#standard-encodings\n",
    "# utf-8 doesnt work when you use it to decode. https://stackoverflow.com/questions/40388792/how-to-decode-a-numpy-array-of-encoded-literals-strings-in-python3-attributeerr\n",
    "# why we have to decode instead of encode - https://stackoverflow.com/questions/28947607/ascii-codec-cant-decode-byte-0xe9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image[5].decode(\"iso-8859-1\") - AttributeError: 'numpy.ndarray' object has no attribute 'decode'\n",
    "# have to do np.char.decode since it is a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(10):\n",
    "#    image[5][i] = np.char.decode(image[5][i],\"iso-8859-1\")\n",
    "#    print(image[5][i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean data by reducing the array dimensionality to 1 and change the S datatypes to string. Since we are dealing with French and other non-English characters, convert the bytes data type to a string using a different encoding than the default UTF-8. Instead use, ISO-8859-1 to conver the bytes to a string. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error for concat description and description. ASCII is compatible with UTF-8 (8 Bytes) but dataset contains non-ASCII so need to use a different encoding. \n",
    "UnicodeDecodeError: 'ascii' codec can't decode byte 0xe9 in position 105: ordinal not in range(128). \n",
    "UnicodeDecodeError: 'ascii' codec can't decode byte generally happens when you try to convert a Python 2.x str that contains non-ASCII to a Unicode string without specifying the encoding of the original string.\n",
    "https://stackoverflow.com/questions/21129020/how-to-fix-unicodedecodeerror-ascii-codec-cant-decode-byte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UTF-8 is one of the most commonly used encodings, and Python often defaults to using it. UTF stands for “Unicode Transformation Format”, and the ‘8’ means that 8-bit values are used in the encoding. (There are also UTF-16 and UTF-32 encodings, but they are less frequently used than UTF-8.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert input_brand S100 dtype to string\n",
    "image[2] = image[2].astype(str)\n",
    "# convert input_category S100 dtype to string\n",
    "image[3] = image[3].astype(str)\n",
    "# convert input_composition S200 dtype to string\n",
    "image[4] = image[4].astype(str)\n",
    "# convert input_concat_description S800 dtype to string\n",
    "image[5] = image[5].astype(str)\n",
    "# convert input_department S100 dtype to string\n",
    "image[6] = image[6].astype(str)\n",
    "# convert input_description S400 dtype to string\n",
    "image[7] = image[7].astype(str)\n",
    "# convert input_gender S30 dtype to string\n",
    "image[8] = image[8].astype(str)\n",
    "# convert input_name S100 dtype to string\n",
    "image[11] = image[11].astype(str)\n",
    "# convert input_pose S40 dtype to string\n",
    "image[12] = image[12].astype(str)\n",
    "# convert input_season S10 dtype to string\n",
    "image[14] = image[14].astype(str)\n",
    "# convert input_subcategory S100 dtype to string\n",
    "image[15] = image[15].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert index 2d arrays to 1d arrays \n",
    "image[0] = image[0].flatten()\n",
    "# convert input_brand 2d arrays to 1d arrays \n",
    "image[2] = image[2].flatten()\n",
    "# convert input_category 2d arrays to 1d arrays \n",
    "image[3] = image[3].flatten()\n",
    "# convert input_composition 2d arrays to 1d arrays \n",
    "image[4] = image[4].flatten()\n",
    "# convert input_concat_description 2d arrays to 1d arrays \n",
    "image[5] = image[5].flatten()\n",
    "# convert input_department 2d arrays to 1d arrays \n",
    "image[6] = image[6].flatten()\n",
    "# convert input_description 2d arrays to 1d arrays \n",
    "image[7] = image[7].flatten()\n",
    "# convert input_gender 2d arrays to 1d arrays \n",
    "image[8] = image[8].flatten()\n",
    "# convert input_msrpUSD 2d arrays to 1d arrays \n",
    "image[10] = image[10].flatten()\n",
    "# convert input_name 2d arrays to 1d arrays \n",
    "image[11] = image[11].flatten()\n",
    "# convert input_pose 2d arrays to 1d arrays \n",
    "image[12] = image[12].flatten()\n",
    "# convert input_productID 2d arrays to 1d arrays \n",
    "image[13] = image[13].flatten()\n",
    "# convert input_season 2d arrays to 1d arrays \n",
    "image[14] = image[14].flatten()\n",
    "# convert input_subcategory 2d arrays to 1d arrays \n",
    "image[15] = image[15].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other altenatives to convert numpy array to a dataframe\n",
    "#df = pd.DataFrame(np.concatenate([arr1, arr2, arr3], axis=1), columns= ['a','b','c'])\n",
    "\n",
    "#column_series = pd.Series(image[2])\n",
    "#df = df.assign(column_name=column_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create empty dataframe \n",
    "df_image = pd.DataFrame()\n",
    "\n",
    "#Split up the task due to this error  - AssertionError: Shape of new values must be compatible with manager shape\n",
    "# add first nine columns to dataframe\n",
    "for i in range(9):\n",
    "    # convert numpy array to list \n",
    "    df_list = image[i]\n",
    "    # add new column to a \n",
    "    df_image[list_of_all_features[i]] = df_list\n",
    "# add last six columns to dataframe\n",
    "for i in range(10,16):\n",
    "    df_list = image[i]\n",
    "    # add new column to a \n",
    "    df_image[list_of_all_features[i]] = df_list\n",
    "df_image.head()\n",
    "#read_hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add input_image to dataframe \n",
    "df_list = image[9].tolist()\n",
    "df_image['input_image'] = df_list\n",
    "df_image.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get rid of duplicates - keep first image of each product "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image = df_image.drop_duplicates(subset =\"input_productID\", \n",
    "                     keep = 'first', inplace = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, some of the string values above are all in capital letters. We can reformmat these columns to a standard format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format strings from all caps to lowercase and capitalize first letter of each word\n",
    "df_image['input_category'] = df_image['input_category'].str.lower().str.title()\n",
    "# format strings from all caps to lowercase and capitalize first letter of each word\n",
    "df_image['input_department'] = df_image['input_department'].str.lower().str.title()\n",
    "# format strings from all caps to lowercase and capitalize first letter of each word\n",
    "df_image['input_subcategory'] = df_image['input_subcategory'].str.lower().str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_image.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_image.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check for null values\n",
    "df_image.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if values in index column are unique \n",
    "df_image['index'].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if values in index_2 column are unique \n",
    "df_image['index_2'].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if values in input_productID column are unique \n",
    "df_image['input_productID'].is_unique  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are multiple images for each product stored in the dataset there is not a unique product id for each row. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy Array to Image Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "# array is currently stored as an object list in the dataframe\n",
    "def show_image(list):\n",
    "    #convert list to a numpy array \n",
    "    #Image needs unsigned bytes, convert datatype from object to uint8\n",
    "    array = np.array(list).astype('uint8')\n",
    "    return Image.fromarray(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_image[:20].iterrows():\n",
    "    display(show_image(row['input_image']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import display\n",
    "#for i in range(0,5):\n",
    "#    display(show_image(df_image['input_image'][i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Input Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the list of stop words that are downloaded from nltk lib.\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print ('list of stop words:', stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_preprocessing(total_text, index, column):\n",
    "    if type(total_text) is not int:\n",
    "        string = \"\"\n",
    "        for words in total_text.split():\n",
    "            # remove the special chars in review like '\"#$@!%^&*()_+-~?>< etc.\n",
    "            word = (\"\".join(e for e in words if e.isalnum()))\n",
    "            # Conver all letters to lower-case\n",
    "            word = word.lower()\n",
    "            # stop-word removal\n",
    "            if not word in stop_words:\n",
    "                string += word + \" \"\n",
    "        df_image[column][index] = string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.clock()\n",
    "# we take each title and we text-preprocess it.\n",
    "for index, row in df_image.iterrows():\n",
    "    nlp_preprocessing(row['input_name'], index, 'input_name')\n",
    "# we print the time it took to preprocess whole titles \n",
    "print(time.clock() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text based product similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Functions which we will use through the rest of the workshop.\n",
    "def show_image(list,ax,fig):\n",
    "    #convert list to a numpy array \n",
    "    #Image needs unsigned bytes, convert datatype from object to uint8\n",
    "    array = np.array(list).astype('uint8')\n",
    "    #Image.fromarray(array)\n",
    "    plt.imshow(array)\n",
    "#plt.show()\n",
    "#Display an image\n",
    "def display_img(list,ax,fig):\n",
    "    # we get the url of the apparel and download it\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    # we will display it in notebook \n",
    "    plt.imshow(img)\n",
    "  \n",
    "#plotting code to understand the algorithm's decision.\n",
    "def plot_heatmap(keys, values, labels, list_image, text):\n",
    "        # keys: list of words of recommended title\n",
    "        # values: len(values) ==  len(keys), values(i) represents the occurence of the word keys(i)\n",
    "        # labels: len(labels) == len(keys), the values of labels depends on the model we are using\n",
    "                # if model == 'bag of words': labels(i) = values(i)\n",
    "                # if model == 'tfidf weighted bag of words':labels(i) = tfidf(keys(i))\n",
    "                # if model == 'idf weighted bag of words':labels(i) = idf(keys(i))\n",
    "        # url : apparel's url\n",
    "\n",
    "        # we will devide the whole figure into two parts\n",
    "        gs = gridspec.GridSpec(2, 2, width_ratios=[4,1], height_ratios=[4,1]) \n",
    "        fig = plt.figure(figsize=(25,3))\n",
    "        \n",
    "        # 1st, ploting heat map that represents the count of commonly ocurred words in title2\n",
    "        ax = plt.subplot(gs[0])\n",
    "        # it displays a cell in white color if the word is intersection(lis of words of title1 and list of words of title2), in black if not\n",
    "        ax = sns.heatmap(np.array([values]), annot=np.array([labels]))\n",
    "        ax.set_xticklabels(keys) # set that axis labels as the words of title\n",
    "        ax.set_title(text) # apparel title\n",
    "        \n",
    "        # 2nd, plotting image of the the apparel\n",
    "        ax = plt.subplot(gs[1])\n",
    "        # we don't want any grid lines for image and no labels on x-axis and y-axis\n",
    "        ax.grid(False)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "        # we call dispaly_img based with paramete url\n",
    "        show_image(list_image, ax, fig)\n",
    "        #display_img(url, ax, fig)\n",
    "        \n",
    "        # displays combine figure ( heat map and image together)\n",
    "        plt.show()\n",
    "    \n",
    "def plot_heatmap_image(doc_id, vec1, vec2, list_image, text, model):\n",
    "\n",
    "    # doc_id : index of the title1\n",
    "    # vec1 : input apparels's vector, it is of a dict type {word:count}\n",
    "    # vec2 : recommended apparels's vector, it is of a dict type {word:count}\n",
    "    # url : apparels image url\n",
    "    # text: title of recomonded apparel (used to keep title of image)\n",
    "    # model, it can be any of the models, \n",
    "        # 1. bag_of_words\n",
    "        # 2. tfidf\n",
    "        # 3. idf\n",
    "\n",
    "    # we find the common words in both titles, because these only words contribute to the distance between two title vec's\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys()) \n",
    "\n",
    "    # we set the values of non intersecting words to zero, this is just to show the difference in heatmap\n",
    "    for i in vec2:\n",
    "        if i not in intersection:\n",
    "            vec2[i]=0\n",
    "\n",
    "    # for labeling heatmap, keys contains list of all words in title2\n",
    "    keys = list(vec2.keys())\n",
    "    #  if ith word in intersection(lis of words of title1 and list of words of title2): values(i)=count of that word in title2 else values(i)=0 \n",
    "    values = [vec2[x] for x in vec2.keys()]\n",
    "    \n",
    "    # labels: len(labels) == len(keys), the values of labels depends on the model we are using\n",
    "        # if model == 'bag of words': labels(i) = values(i)\n",
    "        # if model == 'tfidf weighted bag of words':labels(i) = tfidf(keys(i))\n",
    "        # if model == 'idf weighted bag of words':labels(i) = idf(keys(i))\n",
    "\n",
    "    if model == 'bag_of_words':\n",
    "        labels = values\n",
    "    elif model == 'tfidf':\n",
    "        labels = []\n",
    "        for x in vec2.keys():\n",
    "            # tfidf_title_vectorizer.vocabulary_ it contains all the words in the corpus\n",
    "            # tfidf_title_features[doc_id, index_of_word_in_corpus] will give the tfidf value of word in given document (doc_id)\n",
    "            if x in  tfidf_title_vectorizer.vocabulary_:\n",
    "                labels.append(tfidf_title_features[doc_id, tfidf_title_vectorizer.vocabulary_[x]])\n",
    "            else:\n",
    "                labels.append(0)\n",
    "    elif model == 'idf':\n",
    "        labels = []\n",
    "        for x in vec2.keys():\n",
    "            # idf_title_vectorizer.vocabulary_ it contains all the words in the corpus\n",
    "            # idf_title_features[doc_id, index_of_word_in_corpus] will give the idf value of word in given document (doc_id)\n",
    "            if x in  idf_title_vectorizer.vocabulary_:\n",
    "                labels.append(idf_title_features[doc_id, idf_title_vectorizer.vocabulary_[x]])\n",
    "            else:\n",
    "                labels.append(0)\n",
    "\n",
    "    plot_heatmap(keys, values, labels, list_image, text)\n",
    "\n",
    "\n",
    "# this function gets a list of wrods along with the frequency of each \n",
    "# word given \"text\"\n",
    "def text_to_vector(text):\n",
    "    word = re.compile(r'\\w+')\n",
    "    words = word.findall(text)\n",
    "    # words stores list of all words in given string, you can try 'words = text.split()' this will also gives same result\n",
    "    return Counter(words) # Counter counts the occurence of each word in list, it returns dict type object {word1:count}\n",
    "\n",
    "\n",
    "\n",
    "def get_result(doc_id, content_a, content_b, list_image, model):\n",
    "    text1 = content_a\n",
    "    text2 = content_b\n",
    "    \n",
    "    # vector1 = dict{word11:#count, word12:#count, etc.}\n",
    "    vector1 = text_to_vector(text1)\n",
    "\n",
    "    # vector1 = dict{word21:#count, word22:#count, etc.}\n",
    "    vector2 = text_to_vector(text2)\n",
    "\n",
    "    plot_heatmap_image(doc_id, vector1, vector2, list_image, text2, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import math\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity  \n",
    "from sklearn.metrics import pairwise_distances\n",
    "from matplotlib import gridspec\n",
    "from scipy.sparse import hstack\n",
    "import plotly\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.graph_objs import Scatter, Layout\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "title_vectorizer = CountVectorizer()\n",
    "title_features   = title_vectorizer.fit_transform(df_image['input_name'])\n",
    "title_features.get_shape() # get number of rows and columns in feature matrix.\n",
    "# title_features.shape = #data_points * #words_in_corpus\n",
    "# CountVectorizer().fit_transform(corpus) returns \n",
    "# the a sparase matrix of dimensions #data_points * #words_in_corpus\n",
    "\n",
    "# What is a sparse vector?\n",
    "\n",
    "# title_features[doc_id, index_of_word_in_corpus] = number of times the word occured in that doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words_model(doc_id, num_results):\n",
    "    # doc_id: apparel's id in given corpus\n",
    "    \n",
    "    # pairwise_dist will store the distance from given input apparel to all remaining apparels\n",
    "    # the metric we used here is cosine, the coside distance is mesured as K(X, Y) = <X, Y> / (||X||*||Y||)\n",
    "    # http://scikit-learn.org/stable/modules/metrics.html#cosine-similarity\n",
    "    pairwise_dist = pairwise_distances(title_features,title_features[doc_id])\n",
    "    \n",
    "    # np.argsort will return indices of the smallest distances\n",
    "    indices = np.argsort(pairwise_dist.flatten())[0:num_results]\n",
    "    #pdists will store the smallest distances\n",
    "    pdists  = np.sort(pairwise_dist.flatten())[0:num_results]\n",
    "\n",
    "    #data frame indices of the 9 smallest distace's\n",
    "    df_indices = list(df_image.index[indices])\n",
    "    \n",
    "    for i in range(0,len(indices)):\n",
    "        # we will pass 1. doc_id, 2. title1, 3. title2, url, model\n",
    "        get_result(indices[i],df_image['input_name'].loc[df_indices[0]], df_image['input_name'].loc[df_indices[i]], df_image['input_image'].loc[df_indices[i]], 'bag_of_words')\n",
    "        print('ProductID :',df_image['input_productID'].loc[df_indices[i]])\n",
    "        print ('Brand:', df_image['input_brand'].loc[df_indices[i]])\n",
    "        print ('Title:', df_image['input_name'].loc[df_indices[i]])\n",
    "        print ('Euclidean similarity with the query image :', pdists[i])\n",
    "        print('='*60)\n",
    "\n",
    "#call the bag-of-words model for a product to get similar products.\n",
    "bag_of_words_model(0, 20) # change the index if you want to.\n",
    "# In the output heat map each value represents the count value \n",
    "# of the label word, the color represents the intersection \n",
    "# with inputs title.\n",
    "\n",
    "#try 12566\n",
    "#try 931"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  TF-IDF based product similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_title_vectorizer = TfidfVectorizer(min_df = 0)\n",
    "tfidf_title_features = tfidf_title_vectorizer.fit_transform(df_image['input_name'])\n",
    "# tfidf_title_features.shape = #data_points * #words_in_corpus\n",
    "# CountVectorizer().fit_transform(courpus) returns the a sparase matrix of dimensions #data_points * #words_in_corpus\n",
    "# tfidf_title_features[doc_id, index_of_word_in_corpus] = tfidf values of the word in given doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_model(doc_id, num_results):\n",
    "    # doc_id: apparel's id in given corpus\n",
    "    \n",
    "    # pairwise_dist will store the distance from given input apparel to all remaining apparels\n",
    "    # the metric we used here is cosine, the coside distance is mesured as K(X, Y) = <X, Y> / (||X||*||Y||)\n",
    "    # http://scikit-learn.org/stable/modules/metrics.html#cosine-similarity\n",
    "    pairwise_dist = pairwise_distances(tfidf_title_features,tfidf_title_features[doc_id])\n",
    "\n",
    "    # np.argsort will return indices of 9 smallest distances\n",
    "    indices = np.argsort(pairwise_dist.flatten())[0:num_results]\n",
    "    #pdists will store the 9 smallest distances\n",
    "    pdists  = np.sort(pairwise_dist.flatten())[0:num_results]\n",
    "\n",
    "    #data frame indices of the 9 smallest distace's\n",
    "    df_indices = list(df_image.index[indices])\n",
    "\n",
    "    for i in range(0,len(indices)):\n",
    "        # we will pass 1. doc_id, 2. title1, 3. title2, url, model\n",
    "        get_result(indices[i],df_image['input_name'].loc[df_indices[0]], df_image['input_name'].loc[df_indices[i]], df_image['input_image'].loc[df_indices[i]], 'tfidf')\n",
    "        print('ProductID :',df_image['input_productID'].loc[df_indices[i]])\n",
    "        print ('Brand:', df_image['input_brand'].loc[df_indices[i]])\n",
    "        print ('Title:', df_image['input_name'].loc[df_indices[i]])\n",
    "        print ('Euclidean similarity with the query image :', pdists[i])\n",
    "        print('='*125)\n",
    "tfidf_model(1, 10)\n",
    "# in the output heat map each value represents the tfidf values of the label word, the color represents the intersection with inputs title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 100,000 rows and 15 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input_brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image['input_brand'].describe()\n",
    "#plot distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image['input_brand'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image['input_category'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image['input_category'].value_counts()\n",
    "\n",
    "sns.distplot(df_image['input_category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input_composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image['input_composition'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image['input_composition'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input_concat_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_concat_description'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_concat_description'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input_department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_department'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_department'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_description'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_description'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_gender'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input_msrpUSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_msrpUSD'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image['input_msrpUSD'].value_counts()\n",
    "sns.distplot(df_image['input_msrpUSD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_image['input_msrpUSD'], kde=False, rug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image['input_name'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image['input_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_pose'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_pose'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input_productID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_productID'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_productID'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image['input_season'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image['input_season'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input_subcategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_subcategory'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['input_subcategory'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordcloud for Input Descriptions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def show_wordcloud(data, title = None):\n",
    "    wordcloud = WordCloud(\n",
    "        background_color = 'white',\n",
    "        max_words = 200,\n",
    "        max_font_size = 40, \n",
    "        scale = 3,\n",
    "        random_state = 42\n",
    "    ).generate(str(data))\n",
    "\n",
    "    fig = plt.figure(1, figsize = (20, 20))\n",
    "    plt.axis('off')\n",
    "    if title: \n",
    "        fig.suptitle(title, fontsize = 20)\n",
    "        fig.subplots_adjust(top = 2.3)\n",
    "\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.show()\n",
    "    \n",
    "# print wordcloud\n",
    "show_wordcloud(df_image[\"input_description\"])\n",
    "\n",
    "# command prompt - python -m pip install wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordcloud for Input Concat Descriptions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(df_image[\"input_concat_description\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordcloud for Input Name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_wordcloud(df_image[\"input_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
